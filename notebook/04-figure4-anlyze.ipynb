{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook visualize the p-vals across all tumors\n",
    "# This notebook start from the non-exp gene mapping in expression file\n",
    "import pandas as pd\n",
    "import os, pickle, shutil, time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the label dictionary\n",
    "dir_cohort = '../anno_ref/cohorts'\n",
    "feature_type = 'histology'\n",
    "df_feat = pd.read_csv(os.path.join(dir_cohort,feature_type+'.csv'))\n",
    "dict_feat_np = dict(Counter(df_feat[feature_type]))\n",
    "dict_feat_np = {k: v for k, v in sorted(dict_feat_np.items(), key=lambda item: item[1])}\n",
    "lfeat = list(dict_feat_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Save sig_genes.txt paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For feature type, get the number of successfully run \n",
    "dir_res = '../mutsig_out/'\n",
    "dir_cohort = '../anno_ref/cohorts'\n",
    "dir_anlyze = '../mutsig_out/anlyze'\n",
    "def get_res_path(feature_type, run,  syn_nsyn = None):\n",
    "    dir_res_feat = os.path.join(dir_res,syn_nsyn,run,feature_type)\n",
    "\n",
    "    # Append the path of significant gene files into a list\n",
    "    lsig_f = []\n",
    "    for feat in os.listdir(dir_res_feat):\n",
    "        fsig = [i for i in os.listdir(os.path.join(dir_res_feat,feat)) \\\n",
    "                if i.endswith('sig_genes.txt')]\n",
    "        if len(fsig) > 0: \n",
    "            fsig_path = os.path.join(dir_res_feat, feat, fsig[0])\n",
    "            lsig_f.append(fsig_path)\n",
    "#     pickle.dump(lsig_f, open(os.path.join(dir_anlyze, \\\n",
    "#             feature_type+'.'+syn_nsyn+'.sig_genes.pathlist.'+run+'.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['histology','organ','origin','system','pancancer']\n",
    "get_res_path('histology', 'cohort_072221', 'syn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Get failed cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path\n",
    "dir_res = '../mutsig_out/'\n",
    "dir_cohort = '../anno_ref/cohorts'\n",
    "dir_anlyze = '../mutsig_out/anlyze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below feats failed['Cervix-AdenoCA', 'Breast-DCIS', 'Myeloid-MDS', 'Bone-Cart', 'Bone-Osteoblast', 'Bone-Benign']\n"
     ]
    }
   ],
   "source": [
    "def get_failed_cohort(feature_type,run, syn_nsyn):\n",
    "    # Read feat info df\n",
    "    df_feat = pd.read_csv(os.path.join(dir_cohort, feature_type+'.csv'))\n",
    "\n",
    "    # Get dictionary of feat-patient number and sort by patient number\n",
    "    dict_feat_np = dict(Counter(df_feat[feature_type]))\n",
    "    dict_feat_np = {k: v for k, v in sorted(dict_feat_np.items(), key=lambda item: item[1])}\n",
    "#     print(dict_feat_np)\n",
    "\n",
    "    # Read sig file path list\n",
    "    pathlist = pickle.load(open(os.path.join(dir_anlyze, feature_type+'.'+syn_nsyn+'.sig_genes.pathlist.'+run+'.pkl'),'rb'))\n",
    "\n",
    "    # Calculated features\n",
    "    feat_calced = [i.split('/')[-1].split('.')[0] for i in pathlist]\n",
    "\n",
    "    # The following features are failed because of too little patients\n",
    "    feat_failed = [i for i in df_feat[feature_type].unique() if i not in feat_calced ]\n",
    "    print(f'The below feats failed{feat_failed}')\n",
    "    \n",
    "# features = ['histology','organ','origin','system','pancancer']\n",
    "# for feature in features:\n",
    "#     get_failed_cohort(feature, 'nsyn')\n",
    "# get_failed_cohort('histology','nsyn')\n",
    "get_failed_cohort('histology','cohort_072221','syn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find badx genes - should print nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_res = '../mutsig_out/'\n",
    "def get_badx_genes(feature_type, run, syn_nsyn = None):\n",
    "    dir_res_feat = os.path.join(dir_res,syn_nsyn,run,feature_type)\n",
    "\n",
    "    # Append the path of significant gene files into a list\n",
    "    lsig_f = []\n",
    "    for feat in os.listdir(dir_res_feat):\n",
    "        fbadx = [i for i in os.listdir(os.path.join(dir_res_feat,feat)) \\\n",
    "                if i.endswith('sig_genes.txt.badx.txt')]\n",
    "        if len(fbadx) > 0: \n",
    "            fbadx_path = os.path.join(dir_res_feat, feat, fbadx[0])\n",
    "            if os.stat(fbadx_path).st_size != 0:\n",
    "                print(f'{feat} has low quality genes')\n",
    "                with open(fbadx_path, 'r') as f:\n",
    "                    for lines in f: print(lines)\n",
    "\n",
    "get_badx_genes('histology','cohort_072221','syn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Find and save common non-exp genes in all tumor types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filepath\n",
    "exp_dir = '../anno_ref/ICGC/pcawg_rnaseq/'\n",
    "gene_tophat = 'tophat_star_fpkm.v2.aliquot_gl.tsv'\n",
    "gene_tophatuq = 'tophat_star_fpkm_uq.v2_aliquot_gl.tsv'\n",
    "\n",
    "# Out dir \n",
    "dir_out = './figure4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read aliquot id information\n",
    "df_exp_info = pd.read_csv(os.path.join(exp_dir,'rnaseq.metadata.tsv'), sep = '\\t')\n",
    "\n",
    "# Read expression information\n",
    "df_exp_uq = pd.read_csv(os.path.join(exp_dir,gene_tophatuq),sep = '\\t', index_col = 0)\n",
    "df_exp = pd.read_csv(os.path.join(exp_dir,gene_tophat),sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find genes not expressed in all tumor samples (FPKM-UQ <1)\n",
    "def get_nexp_genes(run = None, threshold = None):\n",
    "    global df_exp_info, df_exp_uq, dir_out\n",
    "    df_tumor_exp_info = df_exp_info[df_exp_info['tumor.normal']=='tumor']\n",
    "    ltumor_id = df_tumor_exp_info['aliquot_id'].tolist()\n",
    "#     df_exp_uq_tumor = df_exp_uq[ltumor_id]\n",
    "    df_exp_tumor = df_exp[ltumor_id]\n",
    "#     nonexp_genes = df_exp_uq_tumor[df_exp_uq_tumor<0.5].dropna().index.tolist()\n",
    "    nonexp_genes = df_exp_tumor[df_exp_tumor<threshold].dropna().index.tolist()\n",
    "    \n",
    "    # Save the gene list to convert gene id to gene name\n",
    "#     with open(os.path.join(dir_out,'nonexp_id_to_name','nonexp-ids_'+run+'_'+str(threshold)+'.csv'), 'w') as f:\n",
    "#         f.write('gene'+'\\n')\n",
    "#         for genes in nonexp_genes:\n",
    "#             f.write(genes+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nexp_genes(run = '072221', threshold = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted gene name of nonexp genes in R  \n",
    "Currently in Dropbox folder, will upload later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get p-val's from all feats -- For FDR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 1057 non-expressed genes out of 19225 genes\n"
     ]
    }
   ],
   "source": [
    "### Read non-expressed gene name file\n",
    "threshold = 1\n",
    "dir_name = './figure4/nonexp_id_to_name/out'\n",
    "df_ne_gene = pd.read_csv(os.path.join(dir_name,'nonexp-names_072221_'+str(threshold)+'.csv'))\n",
    "lne = df_ne_gene['genes']\n",
    "\n",
    "# Read all gene list\n",
    "lgene = pickle.load(open('../anno_ref/proc_refs/gene_name_list_062121.pkl','rb'))\n",
    "print(f'There are total {len(set(lgene).intersection(set(lne)))} \\\n",
    "non-expressed genes out of {len(lgene)} genes')\n",
    "\n",
    "cohort = ['histology','organ','origin','system','pancancer']\n",
    "dir_anlyze = '../mutsig_out/anlyze'\n",
    "dir_out = './figure4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get pvals -- input for FDR calculation\n",
    "def get_allpvals(feature_type,run, syn_nsyn, threshold):\n",
    "    # Read nonexpressed gene file\n",
    "    dir_name = './figure4/nonexp_id_to_name/out'\n",
    "    df_ne_gene = pd.read_csv(os.path.join(dir_name,'nonexp-names_072221_'+str(threshold)+'.csv'))\n",
    "    lne = df_ne_gene['genes']\n",
    "    \n",
    "    df_exp = pd.DataFrame(); df_ne = pd.DataFrame()\n",
    "\n",
    "    sig_pathlist = pickle.load(open(os.path.join(dir_anlyze, feature_type +'.'+syn_nsyn+'.sig_genes.pathlist.'+run+'.pkl'),'rb'))\n",
    "    for fpath in sig_pathlist:\n",
    "        df_res_feat = pd.read_csv(fpath,sep = '\\t')\n",
    "        df_res_feat['feature'] = fpath.split('/')[-1].split('.')[0]\n",
    "        df_nonexp_p = df_res_feat[df_res_feat['gene'].isin(lne)][['gene','p','q','feature']].reset_index(drop = True)\n",
    "        df_nonexp_p['exp/nonexp'] = 'nonexp'\n",
    "        df_exp_p = df_res_feat[~df_res_feat['gene'].isin(lne)][['gene','p','q','feature']].reset_index(drop = True)\n",
    "        df_exp_p['exp/nonexp'] = 'exp'\n",
    "        \n",
    "        df_exp = pd.concat([df_exp,df_exp_p], ignore_index = True)\n",
    "        df_ne = pd.concat([df_ne,df_nonexp_p], ignore_index = True)\n",
    "        \n",
    "\n",
    "    df_all = pd.concat([df_exp,df_ne], ignore_index = True)\n",
    "\n",
    "#     Save all p-val dataframe\n",
    "#     df_all.to_csv(os.path.join(dir_out,feature_type+'.'+syn_nsyn+'.df_all_forFDR.'+run+'.'+threshold+'.csv'))\n",
    "    return df_all\n",
    "\n",
    "# for feat in cohort:\n",
    "#     get_allpvals(feat,'syn')\n",
    "df = get_allpvals('histology','cohort_072221','syn', '5')\n",
    "df = get_allpvals('histology','cohort_072221','syn', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### FDR calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Get nsyn q-value for heatmap -- in figure3-anlyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Candidate number between synonymous and non-synonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = ['histology','organ','origin','system','pancancer']\n",
    "dir_out = './figure4/'\n",
    "dir_anlyze = '../mutsig_out/anlyze'\n",
    "\n",
    "#Load synonymous result\n",
    "feature_type = 'histology';syn_nsyn = 'syn';run = 'cohort_072221';threshold =1;\n",
    "syn_pathlist = pickle.load(open(os.path.join(dir_anlyze, feature_type+'.'+syn_nsyn+'.sig_genes.pathlist.'+run+'.pkl'),'rb'))\n",
    "lfeat_syn = [i.split('/')[-1].split('.')[0] for i in syn_pathlist]\n",
    "df_syn = pd.read_csv(os.path.join(dir_out,feature_type+'.syn.df_all_forheatmap.'+run+'.'+str(threshold)+'.csv'),\\\n",
    "                     index_col = 0)\n",
    "\n",
    "#Load nonsynonymous result\n",
    "feature_type = 'histology';syn_nsyn = 'nsyn';run = 'cohort_072221'\n",
    "nsyn_pathlist = pickle.load(open(os.path.join(dir_anlyze, feature_type+'.'+syn_nsyn+'.sig_genes.pathlist.'+run+'.pkl'),'rb'))\n",
    "lfeat = [i.split('/')[-1].split('.')[0] for i in nsyn_pathlist]\n",
    "df_nsyn = pd.read_csv(os.path.join(dir_out,feature_type+'.nsyn.df_all_forheatmap.'+run+'.csv'),\\\n",
    "                      index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Build dataframe for histology types |syn candidates |nonsyn candidates\n",
    "df = pd.DataFrame(columns = ['syn','nsyn','np'], index = lfeat)\n",
    "for feat in lfeat:\n",
    "    nsig_syn = len(df_syn[df_syn['feature'] == feat])\n",
    "    nsig_nsyn = len(df_nsyn[df_nsyn['feature'] == feat])\n",
    "    df.loc[feat, 'syn'] = nsig_syn\n",
    "    df.loc[feat,'nsyn'] = nsig_nsyn\n",
    "df = df[['syn','nsyn']]\n",
    "df = pd.melt(df.reset_index(), id_vars='index', var_name=\"syn.nsyn\", value_name=\"nsig\") \n",
    "# Append patient number to each histology types\n",
    "for feat in lfeat:\n",
    "    idx = df[df['index'] == feat].index\n",
    "    df.loc[idx, 'index'] = '(n='+str(dict_feat_np[feat])+') '+feat\n",
    "# Save file\n",
    "df.columns = [feature_type, 'syn.nsyn','nsig']\n",
    "# df.to_csv(os.path.join(dir_out, feature_type+'.syn_nsyn.'+run+'.nsig.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
