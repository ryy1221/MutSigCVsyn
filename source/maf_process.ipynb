{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592f9c36-20f6-4d91-8ab7-bd393b06bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script is for maf file processing\n",
    "### 1. MAF files are splitted into individual files\n",
    "### 2. Mutation categories are assigned to individuals\n",
    "### 3. Individual files are merged into histology files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65029993-5ea0-404a-a742-29d1e1965378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from maf_utils import*\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd4a3c93-3ff8-479e-b32c-1b56de10ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3421a9bc-9ce8-46cd-8add-ded7c0ac78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define maf\n",
    "class maf_process:\n",
    "    def __init__(self, params):\n",
    "        self.dir_maf_split = params['dir_maf_split']\n",
    "        self.dir_out = params['dir_out']\n",
    "        self.dir_out_intermediate = params['dir_out_intermediate']\n",
    "        self.dir_out_intermediate_ind_split = os.path.join(params['dir_out_intermediate'],'individual/split/')\n",
    "        self.dir_out_intermediate_ind_categ = os.path.join(params['dir_out_intermediate'],'individual/categ/')\n",
    "        self.ncore = params['parallelize_core']\n",
    "        \n",
    "        ### reference folder and files\n",
    "        self.dir_ref = '../data/proc_refs/'\n",
    "        self.fname_patient_list = 'list_all_patients_102121.pkl'\n",
    "        self.histology_dfname = 'histology.csv'\n",
    "        self.histology_nohype_dfname = 'histology_nohypermutator.csv'\n",
    "        ### output folder and intermediate folder\n",
    "        if not os.path.exists(self.dir_out):\n",
    "            os.makedirs(self.dir_out)\n",
    "        if not os.path.exists(self.dir_out_intermediate):\n",
    "            os.makedirs(self.dir_out_intermediate)\n",
    "        if not os.path.exists(self.dir_out_intermediate_ind_split):\n",
    "            os.makedirs(self.dir_out_intermediate_ind_split)\n",
    "        if not os.path.exists(self.dir_out_intermediate_ind_categ):\n",
    "            os.makedirs(self.dir_out_intermediate_ind_categ)\n",
    "            \n",
    "    ###-------------------------\n",
    "    # 1. First create intermediate file individual patient maf files\n",
    "    ###-------------------------    \n",
    "    def run_split_patient(self): # not using multiprocessing...afrain file read/write will confilct\n",
    "        # get the list of splitted maf files\n",
    "        lmaf_split = os.listdir(self.dir_maf_split)\n",
    "        for maf in tqdm(lmaf_split):\n",
    "            split_patient(maf,dir_maf = self.dir_maf_split, dir_out = self.dir_out_intermediate_ind_split)\n",
    "        print('Finish making individual patient maf files...')\n",
    "    \n",
    "    ###-------------------------\n",
    "    # 2. Assign mutation category to individual patients\n",
    "    ###-------------------------    \n",
    "    def run_assign_categ(self):\n",
    "        ### Get the all patient lists\n",
    "        self.patient_list = pickle.load(open(os.path.join(self.dir_ref,self.fname_patient_list), 'rb'))\n",
    "        print('Start assigning categ to individual patients...')\n",
    "        processes = []\n",
    "        \n",
    "        ### Multiprocessing\n",
    "        for patients in self.patient_list:\n",
    "            p = mp.Process()\n",
    "            function1 = partial(categ_assign,dir_ind = self.dir_out_intermediate_ind_split,\\\n",
    "                           dir_categ_out = self.dir_out_intermediate_ind_categ)\n",
    "            p = mp.Process(target=function1, args=(patients,))\n",
    "            processes.append(p)\n",
    "        [x.start() for x in processes]\n",
    "\n",
    "        \n",
    "        ### Not multiprocessing\n",
    "        # for patients in self.patient_list:\n",
    "        #     categ_assign(patients,dir_ind = self.dir_out_intermediate_ind_split,\\\n",
    "        #                    dir_categ_out = self.dir_out_intermediate_ind_categ )\n",
    "\n",
    "        print('Finish assigning categ to individual patients...')\n",
    "    \n",
    "    ###-------------------------\n",
    "    # 3. Merge individual mutation file to histology mutation files\n",
    "    ###-------------------------    \n",
    "    def load_histology_info(self):\n",
    "        print('Loading histology cohort & gene reference data')\n",
    "        self.histology_df = pd.read_csv(os.path.join(self.dir_ref,self.histology_dfname))\n",
    "        self.histology_nohype_df = pd.read_csv(os.path.join(self.dir_ref,self.histology_nohype_dfname))\n",
    "        self.gene_name_list = pickle.load(open(os.path.join(self.dir_ref, self.fname_lgene),'rb'))\n",
    "        print('Finish Loading histology cohort & gene reference data')\n",
    "    \n",
    "    # merge patients\n",
    "    def merge_maf(self, feature, hypermutator = False):\n",
    "        if hypermutator:\n",
    "            df_sample = self.histology_nohype_df\n",
    "            self.dir_out_merged = self.dir_out+'_nohypermutator'\n",
    "            if not os.path.exists(self.dir_out_merged):\n",
    "                os.makedirs(self.dir_out_merged)\n",
    "        else: \n",
    "            df_sample = self.histology_df\n",
    "            self.dir_out_merged = self.dir_out\n",
    "\n",
    "        if os.path.exists(os.path.join(self.dir_out_merged,feature+'.csv')):\n",
    "            print(f'exists{feature}')\n",
    "            return\n",
    "\n",
    "        # Initialize list for append\n",
    "        ldf = []\n",
    "\n",
    "        # Get patient list for histology\n",
    "        df_histology = df_sample[df_sample['histology'] == feature]\n",
    "        lp = df_histology['tumor_aliquot_id'].unique()\n",
    "\n",
    "        #read patient file\n",
    "        for p in tqdm(lp):\n",
    "            df_maf_ind = pd.read_csv(os.path.join(self.dir_out_intermediate_ind_categ,p+'.to_merge.categ.csv'), index_col = 0)\n",
    "            df_maf_ind = df_maf_ind[df_maf_ind['Hugo_Symbol'].isin(self.gene_name_list)] ## Filter genes\n",
    "            ldf.append(df_maf_ind)\n",
    "\n",
    "        df_maf_merged = pd.concat(ldf, axis = 0)\n",
    "        df_maf_merged.to_csv(os.path.join(self.dir_out_merged,feature+'.csv'),sep='\\t', index = False)\n",
    "        print(f'Finish Merging...')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "346d000e-ffdc-4760-8112-d3f23c0d7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_params = {'dir_maf_split': '../maf_raw/maf_split',\n",
    "              'dir_out_intermediate': '../data/maf/intermediate',\n",
    "              'dir_out': '../data/maf/histology',\n",
    "              'parallelize_core':6} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e0c858-0e48-4c13-a3cf-0e65edbbc469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res =  maf_process(maf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25842479-4c7c-4e76-bb94-79592a5b9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split patient file, don't run if you already run\n",
    "res.run_split_patient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25392ba-cf25-411f-b9b7-e9971f14545d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start assigning categ to individual patients...\n",
      "../data/maf/intermediate/individual/categ/93ff786e-0165-4b02-8d27-806d422e93fc.to_merge.categ.csv\n",
      "../data/maf/intermediate/individual/categ/14c5b81d-da49-4db1-9834-77711c2b1d38.to_merge.categ.csv\n",
      "../data/maf/intermediate/individual/categ/c8e961b4-e324-40a2-89f6-736ec3845bc9.to_merge.categ.csv\n",
      "../data/maf/intermediate/individual/categ/2df02f2b-9f1c-4249-b3b4-b03079cd97d9.to_merge.categ.csv\n",
      "../data/maf/intermediate/individual/categ/978ae91e-6ebe-4efa-97ff-cfad511ae7b3.to_merge.categ.csv\n",
      "../data/maf/intermediate/individual/categ/98e8f23c-5970-4fce-9551-4b11a772fe1b.to_merge.categ.csv\n",
      "../data/maf/intermediate/individual/categ/60413de1-6cd2-4f74-8180-3bdd394d6d16.to_merge.categ.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,18,25,29,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "  0%|          | 1/508812 [00:00<23:32:25,  6.00it/s]/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,18,25,29,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "  0%|          | 215/508812 [00:03<1:49:42, 77.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish assigning categ to individual patients...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/978465 [00:02<6:51:23, 39.64it/s]]/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "  0%|          | 121/875500 [00:02<4:58:22, 48.90it/s]/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,18,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "  0%|          | 272/978465 [00:06<6:30:57, 41.70it/s]/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "  0%|          | 1119/508812 [00:14<2:09:23, 65.39it/s] /storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,18,25,29,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "  0%|          | 540/875500 [00:12<4:56:49, 49.13it/s]s]/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/multiprocessing/popen_fork.py:73: DtypeWarning: Columns (2,18,25,29,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  code = process_obj._bootstrap()\n",
      "/storage/home/yur97/anaconda3/envs/mSigsyn/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "  3%|▎         | 28182/875500 [11:35<7:33:42, 31.13it/s]s]"
     ]
    }
   ],
   "source": [
    "### Assign categ to individual patient files, don't run if you already run\n",
    "res.run_assign_categ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f29c5-3644-4b12-8708-dcb2471bfd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = pd.read_csv(os.path.join('../data/proc_refs/histology.csv'))\n",
    "lfeat = df_cohort['histology'].unique()\n",
    "print(lfeat)\n",
    "res = cov_process(cov_params)\n",
    "res.load_histology_info()\n",
    "\n",
    "for histologies in lfeat:\n",
    "    res.merge_maf(histologies, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400311ee-bda1-42d0-b623-8fcaa5992ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for histologies in lfeat:\n",
    "    res.merge_maf(histologies, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
